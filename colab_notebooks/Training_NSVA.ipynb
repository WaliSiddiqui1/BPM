{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyO/MfhjO45MpoAfGVvGvEbi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WaliSiddiqui1/BPM/blob/main/Training_NSVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mounting Google Drive...\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TOespQcBu6L1",
        "outputId": "eaa6dd29-36c6-481f-f038-9349e616947a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WSpnp56FtyNv"
      },
      "outputs": [],
      "source": [
        "# NBA Sports Video Analysis - Simplified Training\n",
        "# Adapted for Google Colab environment\n",
        "\n",
        "# ===== 1. Setup and Dependencies =====\n",
        "\n",
        "!pip install -q webvtt-py\n",
        "!pip install -q rouge\n",
        "!pip install -q nltk\n",
        "!pip install -q transformers\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from datetime import datetime\n",
        "from transformers import BertTokenizer\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
        "from rouge import Rouge\n",
        "\n",
        "# Import nltk packages\n",
        "nltk.download('punkt')\n",
        "\n",
        "# ===== 2. Directory Setup =====\n",
        "# Define paths for data and outputs\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/NSVA_Results/'\n",
        "FEATURES_DIR = os.path.join(BASE_DIR, 'features')\n",
        "ANNOTATIONS_DIR = os.path.join(BASE_DIR, 'annotations')\n",
        "METADATA_DIR = os.path.join(BASE_DIR, 'metadata')\n",
        "CHECKPOINTS_DIR = os.path.join(BASE_DIR, 'checkpoints')\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, 'results')\n",
        "\n",
        "# Create directories if they don't exist\n",
        "for directory in [FEATURES_DIR, ANNOTATIONS_DIR, METADATA_DIR, CHECKPOINTS_DIR, RESULTS_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# ===== 3. Define Simplified Model Architecture =====\n",
        "# Simplified version of the model described in the paper\n",
        "\n",
        "class SimplifiedSportsVideoUnderstandingModel(keras.Model):\n",
        "    \"\"\"\n",
        "    A simplified version of the Sports Video Understanding model from the paper.\n",
        "    This model uses pre-extracted features and focuses on:\n",
        "    1. Encoding global video features (e.g., from ResNet or pre-extracted TimeSformer)\n",
        "    2. Incorporating object-level features (ball, player, basket)\n",
        "    3. Generating captions using a transformer-based decoder\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        max_frames=100,\n",
        "        max_words=30,\n",
        "        embed_dim=256,  # Reduced from 768 in original\n",
        "        num_heads=4,    # Reduced from 12 in original\n",
        "        decoder_layers=2,  # Reduced from 3 in original\n",
        "        dropout_rate=0.1,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(SimplifiedSportsVideoUnderstandingModel, self).__init__(**kwargs)\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_frames = max_frames\n",
        "        self.max_words = max_words\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # Feature projection layers (project pre-extracted features to common dimension)\n",
        "        self.video_projection = keras.layers.Dense(embed_dim)\n",
        "        self.ball_projection = keras.layers.Dense(embed_dim)\n",
        "        self.player_projection = keras.layers.Dense(embed_dim)\n",
        "        self.basket_projection = keras.layers.Dense(embed_dim)\n",
        "        self.court_projection = keras.layers.Dense(embed_dim)\n",
        "\n",
        "        # Temporal aggregation (simpler than TimeSformer)\n",
        "        self.temporal_aggregation = keras.Sequential([\n",
        "            keras.layers.LayerNormalization(epsilon=1e-6),\n",
        "            keras.layers.Bidirectional(keras.layers.LSTM(embed_dim // 2, return_sequences=True)),\n",
        "            keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        ])\n",
        "\n",
        "        # Multi-modal fusion\n",
        "        self.fusion_layer = keras.Sequential([\n",
        "            keras.layers.LayerNormalization(epsilon=1e-6),\n",
        "            keras.layers.Dense(embed_dim * 2, activation='relu'),\n",
        "            keras.layers.Dropout(dropout_rate),\n",
        "            keras.layers.Dense(embed_dim),\n",
        "            keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        ])\n",
        "\n",
        "        # Decoder for caption generation\n",
        "        self.decoder_embedding = keras.layers.Embedding(vocab_size, embed_dim)\n",
        "        self.positional_encoding = PositionalEncoding(max_words, embed_dim)\n",
        "\n",
        "        # Multi-head attention layers for decoder\n",
        "        self.decoder_layers = []\n",
        "        for i in range(decoder_layers):\n",
        "            self.decoder_layers.append(DecoderLayer(\n",
        "                embed_dim, num_heads, embed_dim * 4, dropout_rate\n",
        "            ))\n",
        "\n",
        "        self.decoder_layernorm = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.output_projection = keras.layers.Dense(vocab_size)\n",
        "\n",
        "        # Task-specific heads for additional tasks\n",
        "        self.action_classifier = keras.layers.Dense(14)  # 14 action classes\n",
        "        self.player_classifier = keras.layers.Dense(184)  # 184 player identities\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        \"\"\"Forward pass through the model\"\"\"\n",
        "        (video_features, video_mask,\n",
        "         ball_features, player_features, basket_features, court_features,\n",
        "         input_caption_ids, decoder_mask) = inputs\n",
        "\n",
        "        # Process global video features\n",
        "        video_embed = self.video_projection(video_features)\n",
        "\n",
        "        # Process object features\n",
        "        ball_embed = self.ball_projection(ball_features)\n",
        "\n",
        "        # For player features, we need to average across players\n",
        "        # Reshape from [batch, frames, players, dims] to [batch*frames, players, dims]\n",
        "        batch_size = tf.shape(player_features)[0]\n",
        "        frames = tf.shape(player_features)[1]\n",
        "\n",
        "        player_features_flat = tf.reshape(player_features,\n",
        "                                         [batch_size * frames, -1, tf.shape(player_features)[-1]])\n",
        "        player_embed_flat = self.player_projection(player_features_flat)\n",
        "        # Average over players dimension\n",
        "        player_embed_flat = tf.reduce_mean(player_embed_flat, axis=1)\n",
        "        # Reshape back to [batch, frames, dims]\n",
        "        player_embed = tf.reshape(player_embed_flat, [batch_size, frames, self.embed_dim])\n",
        "\n",
        "        basket_embed = self.basket_projection(basket_features)\n",
        "        court_embed = self.court_projection(court_features)\n",
        "\n",
        "        # Combine features\n",
        "        combined_features = video_embed + ball_embed + player_embed + basket_embed + court_embed\n",
        "\n",
        "        # Apply temporal aggregation\n",
        "        sequence_features = self.temporal_aggregation(combined_features, training=training)\n",
        "\n",
        "        # Apply fusion layer\n",
        "        fused_features = self.fusion_layer(sequence_features, training=training)\n",
        "\n",
        "        # Process through decoder\n",
        "        decoder_embedding = self.decoder_embedding(input_caption_ids)\n",
        "        decoder_embedding = self.positional_encoding(decoder_embedding)\n",
        "\n",
        "        decoder_output = decoder_embedding\n",
        "\n",
        "        # Process through each decoder layer\n",
        "        for decoder_layer in self.decoder_layers:\n",
        "            decoder_output = decoder_layer(\n",
        "                decoder_output,\n",
        "                fused_features,\n",
        "                look_ahead_mask=create_look_ahead_mask(tf.shape(input_caption_ids)[1]),\n",
        "                padding_mask=create_padding_mask(decoder_mask),\n",
        "                encoder_padding_mask=create_padding_mask(video_mask),\n",
        "                training=training\n",
        "            )\n",
        "\n",
        "        decoder_output = self.decoder_layernorm(decoder_output)\n",
        "\n",
        "        # Generate logits\n",
        "        caption_logits = self.output_projection(decoder_output)\n",
        "\n",
        "        # Feature for action and player recognition (use first token of encoder output)\n",
        "        sequence_representation = fused_features[:, 0, :]\n",
        "\n",
        "        # Generate logits for other tasks\n",
        "        action_logits = self.action_classifier(sequence_representation)\n",
        "        player_logits = self.player_classifier(sequence_representation)\n",
        "\n",
        "        return {\n",
        "            \"caption_logits\": caption_logits,\n",
        "            \"action_logits\": action_logits,\n",
        "            \"player_logits\": player_logits,\n",
        "            \"encoder_output\": fused_features\n",
        "        }\n",
        "\n",
        "    def generate_caption(self, encoder_output, tokenizer, max_length=30, beam_size=3):\n",
        "        \"\"\"Generate captions using beam search decoding\"\"\"\n",
        "        batch_size = tf.shape(encoder_output)[0]\n",
        "\n",
        "        # Initialize with start token\n",
        "        start_token = tokenizer.cls_token_id\n",
        "        end_token = tokenizer.sep_token_id\n",
        "\n",
        "        # Initial decoder input and state\n",
        "        decoder_input = tf.expand_dims([start_token] * batch_size, 1)  # [batch_size, 1]\n",
        "        decoder_mask = tf.ones_like(decoder_input)\n",
        "\n",
        "        # Storage for beams\n",
        "        beams = [(decoder_input, 0.0, decoder_mask)]  # (sequence, score, mask)\n",
        "        finished_beams = []\n",
        "\n",
        "        # Beam search\n",
        "        for step in range(max_length - 1):\n",
        "            candidates = []\n",
        "\n",
        "            for seq, score, mask in beams:\n",
        "                # Skip if sequence is finished (has end token)\n",
        "                if seq[0, -1] == end_token:\n",
        "                    finished_beams.append((seq, score, mask))\n",
        "                    continue\n",
        "\n",
        "                # Predict next token\n",
        "                inputs = (\n",
        "                    tf.zeros((batch_size, self.max_frames, 768), dtype=tf.float32),  # Placeholder for video_features - Changed to (batch_size, max_frames, 768)\n",
        "                    tf.ones((batch_size, self.max_frames), dtype=tf.int32),  # video_mask\n",
        "                    tf.zeros((batch_size, self.max_frames, 768), dtype=tf.float32),  # Placeholder for ball_features - Changed to (batch_size, max_frames, 768)\n",
        "                    tf.zeros((batch_size, self.max_frames, 5, 768), dtype=tf.float32),  # Placeholder for player_features - Changed to (batch_size, max_frames, 5, 768)\n",
        "                    tf.zeros((batch_size, self.max_frames, 768), dtype=tf.float32),  # Placeholder for basket_features - Changed to (batch_size, max_frames, 768)\n",
        "                    tf.zeros((batch_size, self.max_frames, 768), dtype=tf.float32),  # Placeholder for court_features - Changed to (batch_size, max_frames, 768)\n",
        "                    seq,\n",
        "                    mask\n",
        "                )\n",
        "\n",
        "                # Get logits from decoder\n",
        "                outputs = self.call(inputs, training=False)\n",
        "                logits = outputs[\"caption_logits\"][:, -1, :]  # Last token prediction\n",
        "\n",
        "                # Get top k tokens\n",
        "                topk_logits, topk_indices = tf.math.top_k(logits, k=beam_size)\n",
        "                topk_probs = tf.nn.softmax(topk_logits)\n",
        "\n",
        "                # Add candidates\n",
        "                for i in range(beam_size):\n",
        "                    token = topk_indices[0, i]\n",
        "                    prob = topk_probs[0, i]\n",
        "\n",
        "                    new_seq = tf.concat([seq, tf.expand_dims([token], 1)], axis=1)\n",
        "                    new_mask = tf.concat([mask, tf.ones((tf.shape(mask)[0], 1), dtype=tf.int32)], axis=1)\n",
        "                    new_score = score - tf.math.log(prob + 1e-10)  # Lower is better (negative log prob)\n",
        "\n",
        "                    candidates.append((new_seq, new_score, new_mask))\n",
        "\n",
        "                    # If end token, add to finished beams\n",
        "                    if token == end_token:\n",
        "                        finished_beams.append((new_seq, new_score, new_mask))\n",
        "\n",
        "            # Keep top beam_size candidates\n",
        "            candidates.sort(key=lambda x: x[1])  # Sort by score (lower is better)\n",
        "            beams = candidates[:beam_size]\n",
        "\n",
        "            # Early stopping if all beams are finished\n",
        "            if all(beam[0][0, -1] == end_token for beam in beams):\n",
        "                break\n",
        "\n",
        "        # Add unfinished beams to finished beams\n",
        "        for beam in beams:\n",
        "            if beam[0][0, -1] != end_token:\n",
        "                finished_beams.append(beam)\n",
        "\n",
        "        # Return the best beam\n",
        "        if finished_beams:\n",
        "            finished_beams.sort(key=lambda x: x[1])  # Sort by score\n",
        "            best_seq = finished_beams[0][0][0].numpy()  # First in batch\n",
        "            caption = tokenizer.decode(best_seq, skip_special_tokens=True)\n",
        "        else:\n",
        "            caption = \"\"\n",
        "\n",
        "        return caption\n",
        "\n",
        "class PositionalEncoding(keras.layers.Layer):\n",
        "    \"\"\"Positional encoding layer for transformer decoder\"\"\"\n",
        "    def __init__(self, max_length, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.max_length = max_length\n",
        "        self.d_model = d_model\n",
        "        self.pos_encoding = self.positional_encoding(max_length, d_model)\n",
        "\n",
        "    def get_angles(self, pos, i, d_model):\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "        return pos * angle_rates\n",
        "\n",
        "    def positional_encoding(self, max_length, d_model):\n",
        "        angle_rads = self.get_angles(\n",
        "            np.arange(max_length)[:, np.newaxis],\n",
        "            np.arange(d_model)[np.newaxis, :],\n",
        "            d_model\n",
        "        )\n",
        "\n",
        "        # Apply sin to even indices in the array; 2i\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "        # Apply cos to odd indices in the array; 2i+1\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        seq_len = tf.shape(inputs)[1]\n",
        "        return inputs + self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "class DecoderLayer(keras.layers.Layer):\n",
        "    \"\"\"Decoder layer with self-attention and cross-attention\"\"\"\n",
        "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.self_attention = keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=d_model // num_heads, dropout=dropout_rate\n",
        "        )\n",
        "        self.cross_attention = keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=d_model // num_heads, dropout=dropout_rate\n",
        "        )\n",
        "\n",
        "        self.ffn = keras.Sequential([\n",
        "            keras.layers.Dense(dff, activation='relu'),\n",
        "            keras.layers.Dense(d_model)\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = keras.layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = keras.layers.Dropout(dropout_rate)\n",
        "        self.dropout3 = keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, inputs, encoder_output, look_ahead_mask=None,\n",
        "             padding_mask=None, encoder_padding_mask=None, training=True):\n",
        "        # Self-attention\n",
        "        attn1 = self.self_attention(\n",
        "            query=inputs,\n",
        "            key=inputs,\n",
        "            value=inputs,\n",
        "            attention_mask=look_ahead_mask,\n",
        "            training=training\n",
        "        )\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn1)\n",
        "\n",
        "        # Cross-attention\n",
        "        attn2 = self.cross_attention(\n",
        "            query=out1,\n",
        "            key=encoder_output,\n",
        "            value=encoder_output,\n",
        "            attention_mask=encoder_padding_mask,\n",
        "            training=training\n",
        "        )\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(out1 + attn2)\n",
        "\n",
        "        # Feed-forward layer\n",
        "        ffn_output = self.ffn(out2, training=training)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(out2 + ffn_output)\n",
        "\n",
        "        return out3\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    \"\"\"Create a look-ahead mask for transformer decoder\"\"\"\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask[tf.newaxis, tf.newaxis, :, :]  # (1, 1, size, size)\n",
        "\n",
        "def create_padding_mask(mask):\n",
        "    \"\"\"Convert a 1D mask to a 2D padding mask for attention\"\"\"\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "# ===== 4. Data Processing and Training Functions =====\n",
        "\n",
        "class NSVADataset:\n",
        "    \"\"\"\n",
        "    Simplified data loader for the NSVA dataset\n",
        "    Loads pre-extracted features and captions\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        annotations_file,\n",
        "        video_features_dir,\n",
        "        ball_features_dir,\n",
        "        player_features_dir,\n",
        "        basket_features_dir,\n",
        "        court_features_dir,\n",
        "        tokenizer,\n",
        "        max_frames=100,\n",
        "        max_words=30,\n",
        "        split='train',\n",
        "        split_file=None\n",
        "    ):\n",
        "        self.video_features_dir = video_features_dir\n",
        "        self.ball_features_dir = ball_features_dir\n",
        "        self.player_features_dir = player_features_dir\n",
        "        self.basket_features_dir = basket_features_dir\n",
        "        self.court_features_dir = court_features_dir\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_frames = max_frames\n",
        "        self.max_words = max_words\n",
        "\n",
        "        # Load annotations\n",
        "        with open(annotations_file, 'r') as f:\n",
        "            self.annotations = json.load(f)\n",
        "\n",
        "        # Load split information\n",
        "        if split_file:\n",
        "            with open(split_file, 'r') as f:\n",
        "                splits = json.load(f)\n",
        "                self.video_ids = splits[split]\n",
        "        else:\n",
        "            # Use all videos if no split file is provided\n",
        "            self.video_ids = list(set([s['video_id'] for s in self.annotations['sentences']]))\n",
        "\n",
        "        # Filter annotations by video IDs in the split\n",
        "        self.filtered_annotations = [\n",
        "            s for s in self.annotations['sentences']\n",
        "            if s['video_id'] in self.video_ids\n",
        "        ]\n",
        "\n",
        "        print(f\"Loaded {len(self.filtered_annotations)} annotations for {len(self.video_ids)} videos in {split} split\")\n",
        "\n",
        "        # Check which videos have features extracted\n",
        "        self.available_videos = set()\n",
        "        for video_id in self.video_ids:\n",
        "            if (\n",
        "                os.path.exists(os.path.join(self.video_features_dir, f\"{video_id}.npy\")) and\n",
        "                os.path.exists(os.path.join(self.ball_features_dir, f\"{video_id}.npy\")) and\n",
        "                os.path.exists(os.path.join(self.player_features_dir, f\"{video_id}.npy\")) and\n",
        "                os.path.exists(os.path.join(self.basket_features_dir, f\"{video_id}.npy\")) and\n",
        "                os.path.exists(os.path.join(self.court_features_dir, f\"{video_id}.npy\"))\n",
        "            ):\n",
        "                self.available_videos.add(video_id)\n",
        "\n",
        "        # Final filter for annotations with available features\n",
        "        self.filtered_annotations = [\n",
        "            s for s in self.filtered_annotations\n",
        "            if s['video_id'] in self.available_videos\n",
        "        ]\n",
        "\n",
        "        print(f\"Found {len(self.available_videos)} videos with extracted features\")\n",
        "        print(f\"Final number of annotations: {len(self.filtered_annotations)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filtered_annotations)\n",
        "\n",
        "    def load_features(self, video_id):\n",
        "        \"\"\"Load all features for a video\"\"\"\n",
        "        video_features = np.load(os.path.join(self.video_features_dir, f\"{video_id}.npy\"))\n",
        "        ball_features = np.load(os.path.join(self.ball_features_dir, f\"{video_id}.npy\"))\n",
        "        player_features = np.load(os.path.join(self.player_features_dir, f\"{video_id}.npy\"))\n",
        "        basket_features = np.load(os.path.join(self.basket_features_dir, f\"{video_id}.npy\"))\n",
        "        court_features = np.load(os.path.join(self.court_features_dir, f\"{video_id}.npy\"))\n",
        "\n",
        "        # Truncate to max_frames\n",
        "        if video_features.shape[0] > self.max_frames:\n",
        "            video_features = video_features[:self.max_frames]\n",
        "            ball_features = ball_features[:self.max_frames]\n",
        "            player_features = player_features[:self.max_frames]\n",
        "            basket_features = basket_features[:self.max_frames]\n",
        "            court_features = court_features[:self.max_frames]\n",
        "\n",
        "        # Create mask\n",
        "        frames = video_features.shape[0]\n",
        "        video_mask = np.ones(frames, dtype=np.int32)\n",
        "\n",
        "        # Pad if necessary\n",
        "        if frames < self.max_frames:\n",
        "            pad_len = self.max_frames - frames\n",
        "\n",
        "            # Pad with zeros\n",
        "            video_features = np.pad(video_features, ((0, pad_len), (0, 0)), mode='constant')\n",
        "            ball_features = np.pad(ball_features, ((0, pad_len), (0, 0)), mode='constant')\n",
        "            player_features = np.pad(player_features, ((0, pad_len), (0, 0), (0, 0)), mode='constant')\n",
        "            basket_features = np.pad(basket_features, ((0, pad_len), (0, 0)), mode='constant')\n",
        "            court_features = np.pad(court_features, ((0, pad_len), (0, 0)), mode='constant')\n",
        "\n",
        "            # Extend mask\n",
        "            video_mask = np.pad(video_mask, (0, pad_len), mode='constant')\n",
        "\n",
        "        return video_features, video_mask, ball_features, player_features, basket_features, court_features\n",
        "\n",
        "    def tokenize_caption(self, caption):\n",
        "        \"\"\"Tokenize caption and create input/output ids for training\"\"\"\n",
        "        # Tokenize\n",
        "        tokenized = self.tokenizer(\n",
        "            caption,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_words,\n",
        "            return_tensors=\"tf\"\n",
        "        )\n",
        "\n",
        "        input_ids = tokenized[\"input_ids\"][0]\n",
        "        attention_mask = tokenized[\"attention_mask\"][0]\n",
        "\n",
        "        # For decoder input, shift right and add start token\n",
        "        decoder_input_ids = tf.concat([\n",
        "            [self.tokenizer.cls_token_id],\n",
        "            input_ids[:-1]\n",
        "        ], axis=0)\n",
        "\n",
        "        # Decoder mask is same as attention mask\n",
        "        decoder_mask = attention_mask\n",
        "\n",
        "        # Target is the original input_ids\n",
        "        target_ids = input_ids\n",
        "\n",
        "        return decoder_input_ids, decoder_mask, target_ids\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Get a single sample from the dataset\"\"\"\n",
        "        annotation = self.filtered_annotations[idx]\n",
        "        video_id = annotation['video_id']\n",
        "        caption = annotation['caption']\n",
        "\n",
        "        # Load features\n",
        "        video_features, video_mask, ball_features, player_features, basket_features, court_features = self.load_features(video_id)\n",
        "\n",
        "        # Tokenize caption\n",
        "        decoder_input_ids, decoder_mask, target_ids = self.tokenize_caption(caption)\n",
        "\n",
        "        return (\n",
        "            video_features.astype(np.float32),\n",
        "            video_mask,\n",
        "            ball_features.astype(np.float32),\n",
        "            player_features.astype(np.float32),\n",
        "            basket_features.astype(np.float32),\n",
        "            court_features.astype(np.float32),\n",
        "            decoder_input_ids,\n",
        "            decoder_mask\n",
        "        ), target_ids\n",
        "\n",
        "    def create_tf_dataset(self, batch_size=32, shuffle=True, buffer_size=1000):\n",
        "        \"\"\"Create a TensorFlow dataset from samples\"\"\"\n",
        "        def generator():\n",
        "            indices = list(range(len(self)))\n",
        "            if shuffle:\n",
        "                import random\n",
        "                random.shuffle(indices)\n",
        "\n",
        "            for idx in indices:\n",
        "                yield self[idx]\n",
        "\n",
        "        # Define output shapes\n",
        "        output_shapes = (\n",
        "            (\n",
        "                tf.TensorShape([self.max_frames, None]),  # video_features\n",
        "                tf.TensorShape([self.max_frames]),  # video_mask\n",
        "                tf.TensorShape([self.max_frames, None]),  # ball_features\n",
        "                tf.TensorShape([self.max_frames, None, None]),  # player_features\n",
        "                tf.TensorShape([self.max_frames, None]),  # basket_features\n",
        "                tf.TensorShape([self.max_frames, None]),  # court_features\n",
        "                tf.TensorShape([self.max_words]),  # decoder_input_ids\n",
        "                tf.TensorShape([self.max_words])   # decoder_mask\n",
        "            ),\n",
        "            tf.TensorShape([self.max_words])  # target_ids\n",
        "        )\n",
        "\n",
        "        # Define output types\n",
        "        output_types = (\n",
        "            (\n",
        "                tf.float32,  # video_features\n",
        "                tf.int32,    # video_mask\n",
        "                tf.float32,  # ball_features\n",
        "                tf.float32,  # player_features\n",
        "                tf.float32,  # basket_features\n",
        "                tf.float32,  # court_features\n",
        "                tf.int32,    # decoder_input_ids\n",
        "                tf.int32     # decoder_mask\n",
        "            ),\n",
        "            tf.int32  # target_ids\n",
        "        )\n",
        "\n",
        "        # Create dataset\n",
        "        dataset = tf.data.Dataset.from_generator(\n",
        "            generator,\n",
        "            output_types=output_types,\n",
        "            output_shapes=output_shapes\n",
        "        )\n",
        "\n",
        "        if shuffle:\n",
        "            dataset = dataset.shuffle(buffer_size)\n",
        "\n",
        "        # Batch and prefetch\n",
        "        dataset = dataset.batch(batch_size)\n",
        "        dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "class NSVATrainer:\n",
        "    \"\"\"Trainer for the NSVA captioning model\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        train_dataset,\n",
        "        val_dataset=None,\n",
        "        learning_rate=1e-4,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        weight_decay=0.01,\n",
        "        checkpoint_dir=None,\n",
        "        log_dir=None\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.train_dataset = train_dataset\n",
        "        self.val_dataset = val_dataset\n",
        "\n",
        "        # Setup optimizer\n",
        "        self.learning_rate = learning_rate\n",
        "        self.optimizer = keras.optimizers.Adam(\n",
        "            learning_rate=learning_rate,\n",
        "            beta_1=beta_1,\n",
        "            beta_2=beta_2\n",
        "        )\n",
        "\n",
        "        # Setup loss function\n",
        "        self.loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
        "            from_logits=True, reduction='none'\n",
        "        )\n",
        "\n",
        "        # Setup metrics\n",
        "        self.train_loss = keras.metrics.Mean(name='train_loss')\n",
        "        self.train_accuracy = keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "        self.val_loss = keras.metrics.Mean(name='val_loss')\n",
        "        self.val_accuracy = keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
        "\n",
        "        # Setup checkpointing\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        if checkpoint_dir:\n",
        "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "            self.checkpoint = tf.train.Checkpoint(\n",
        "                optimizer=self.optimizer,\n",
        "                model=self.model,\n",
        "                step=tf.Variable(0),\n",
        "                epoch=tf.Variable(0)\n",
        "            )\n",
        "            self.checkpoint_manager = tf.train.CheckpointManager(\n",
        "                self.checkpoint, checkpoint_dir, max_to_keep=5\n",
        "            )\n",
        "\n",
        "            self.restore_checkpoint()\n",
        "\n",
        "        # Setup tensorboard\n",
        "        self.log_dir = log_dir\n",
        "        if log_dir:\n",
        "            os.makedirs(log_dir, exist_ok=True)\n",
        "            self.summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "\n",
        "    def restore_checkpoint(self):\n",
        "        \"\"\"Restore from latest checkpoint\"\"\"\n",
        "        if self.checkpoint_manager.latest_checkpoint:\n",
        "            self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
        "            print(f\"Restored from checkpoint: {self.checkpoint_manager.latest_checkpoint}\")\n",
        "            print(f\"Starting from epoch {int(self.checkpoint.epoch.numpy())}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"Initializing from scratch.\")\n",
        "            return False\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, inputs, targets):\n",
        "        \"\"\"Single training step\"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            predictions = self.model(inputs, training=True)\n",
        "            caption_logits = predictions[\"caption_logits\"]\n",
        "\n",
        "            # Calculate loss\n",
        "            mask = tf.cast(inputs[7], tf.float32)  # decoder_mask\n",
        "            loss = self.loss_fn(targets, caption_logits)\n",
        "            loss = tf.reduce_sum(loss * mask) / tf.reduce_sum(mask)\n",
        "\n",
        "        # Backward pass\n",
        "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "\n",
        "        # Apply gradients\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "\n",
        "        # Update metrics\n",
        "        self.train_loss.update_state(loss)\n",
        "        self.train_accuracy.update_state(targets, caption_logits, sample_weight=mask)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    @tf.function\n",
        "    def validate_step(self, inputs, targets):\n",
        "        \"\"\"Single validation step\"\"\"\n",
        "        # Forward pass\n",
        "        predictions = self.model(inputs, training=False)\n",
        "        caption_logits = predictions[\"caption_logits\"]\n",
        "\n",
        "        # Calculate loss\n",
        "        mask = tf.cast(inputs[7], tf.float32)  # decoder_mask\n",
        "        loss = self.loss_fn(targets, caption_logits)\n",
        "        loss = tf.reduce_sum(loss * mask) / tf.reduce_sum(mask)\n",
        "\n",
        "        # Update metrics\n",
        "        self.val_loss.update_state(loss)\n",
        "        self.val_accuracy.update_state(targets, caption_logits, sample_weight=mask)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def train(self, epochs, eval_freq=1):\n",
        "        \"\"\"Train the model for the specified number of epochs\"\"\"\n",
        "        start_epoch = 0\n",
        "        if hasattr(self, 'checkpoint'):\n",
        "            start_epoch = int(self.checkpoint.epoch.numpy())\n",
        "\n",
        "        for epoch in range(start_epoch, start_epoch + epochs):\n",
        "            print(f\"\\nEpoch {epoch + 1}/{start_epoch + epochs}\")\n",
        "\n",
        "            # Reset metrics\n",
        "            self.train_loss.reset_state()\n",
        "            self.train_accuracy.reset_state()\n",
        "\n",
        "            # Training loop\n",
        "            start_time = time.time()\n",
        "            for step, (inputs, targets) in enumerate(self.train_dataset):\n",
        "                loss = self.train_step(inputs, targets)\n",
        "\n",
        "                # Update checkpoint step\n",
        "                if hasattr(self, 'checkpoint'):\n",
        "                    self.checkpoint.step.assign_add(1)\n",
        "\n",
        "                # Print progress\n",
        "                if step % 10 == 0:\n",
        "                    print(f\"Step {step}: Loss = {loss:.4f}, \" +\n",
        "                          f\"Accuracy = {self.train_accuracy.result():.4f}\")\n",
        "\n",
        "            train_time = time.time() - start_time\n",
        "\n",
        "            # Print epoch results\n",
        "            print(f\"Training time: {train_time:.2f}s\")\n",
        "            print(f\"Train Loss: {self.train_loss.result():.4f}\")\n",
        "            print(f\"Train Accuracy: {self.train_accuracy.result():.4f}\")\n",
        "\n",
        "            # Validation\n",
        "            if self.val_dataset and (epoch + 1) % eval_freq == 0:\n",
        "                self.validate()\n",
        "\n",
        "            # Save checkpoint\n",
        "            if hasattr(self, 'checkpoint'):\n",
        "                self.checkpoint.epoch.assign_add(1)\n",
        "                save_path = self.checkpoint_manager.save()\n",
        "                print(f\"Saved checkpoint at: {save_path}\")\n",
        "\n",
        "            # Write to tensorboard\n",
        "            if hasattr(self, 'summary_writer'):\n",
        "                with self.summary_writer.as_default():\n",
        "                    tf.summary.scalar('train_loss', self.train_loss.result(), step=epoch)\n",
        "                    tf.summary.scalar('train_accuracy', self.train_accuracy.result(), step=epoch)\n",
        "\n",
        "                    if self.val_dataset and (epoch + 1) % eval_freq == 0:\n",
        "                        tf.summary.scalar('val_loss', self.val_loss.result(), step=epoch)\n",
        "                        tf.summary.scalar('val_accuracy', self.val_accuracy.result(), step=epoch)\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"Run validation and calculate metrics\"\"\"\n",
        "        print(\"\\nRunning validation...\")\n",
        "\n",
        "        # Reset metrics\n",
        "        self.val_loss.reset_state()\n",
        "        self.val_accuracy.reset_state()\n",
        "\n",
        "        # Validation loop\n",
        "        start_time = time.time()\n",
        "        for inputs, targets in self.val_dataset:\n",
        "            self.validate_step(inputs, targets)\n",
        "\n",
        "        val_time = time.time() - start_time\n",
        "\n",
        "        # Print results\n",
        "        print(f\"Validation time: {val_time:.2f}s\")\n",
        "        print(f\"Validation Loss: {self.val_loss.result():.4f}\")\n",
        "        print(f\"Validation Accuracy: {self.val_accuracy.result():.4f}\")\n",
        "\n",
        "        return self.val_loss.result().numpy()\n",
        "\n",
        "    def evaluate_captions(self, dataset, tokenizer, num_samples=50):\n",
        "        \"\"\"Generate captions and calculate BLEU and ROUGE scores\"\"\"\n",
        "        print(f\"\\nGenerating captions for {num_samples} samples...\")\n",
        "\n",
        "        references = []\n",
        "        hypotheses = []\n",
        "\n",
        "        rouge = Rouge()\n",
        "\n",
        "        for i, (inputs, targets) in enumerate(dataset):\n",
        "            if i >= num_samples:\n",
        "                break\n",
        "\n",
        "            # Get ground truth caption\n",
        "            gt_caption = tokenizer.decode(targets[0].numpy(), skip_special_tokens=True)\n",
        "\n",
        "            # Generate caption\n",
        "            video_features, video_mask, ball_features, player_features, basket_features, court_features, _, _ = inputs\n",
        "\n",
        "            # Forward pass to get encoder output\n",
        "            encoder_inputs = (\n",
        "                video_features, video_mask,\n",
        "                ball_features, player_features, basket_features, court_features,\n",
        "                tf.zeros_like(targets[:1]),\n",
        "                tf.zeros_like(targets[:1])\n",
        "            )\n",
        "\n",
        "            outputs = self.model(encoder_inputs, training=False)\n",
        "            encoder_output = outputs[\"encoder_output\"]\n",
        "\n",
        "            # Generate caption using beam search\n",
        "            pred_caption = self.model.generate_caption(encoder_output, tokenizer)\n",
        "\n",
        "            references.append([gt_caption.split()])\n",
        "            hypotheses.append(pred_caption.split())\n",
        "\n",
        "            # Print examples\n",
        "            if i < 5:\n",
        "                print(f\"\\nExample {i+1}:\")\n",
        "                print(f\"Ground truth: {gt_caption}\")\n",
        "                print(f\"Prediction: {pred_caption}\")\n",
        "\n",
        "        # Calculate BLEU scores\n",
        "        bleu1 = corpus_bleu(references, hypotheses, weights=(1, 0, 0, 0))\n",
        "        bleu2 = corpus_bleu(references, hypotheses, weights=(0.5, 0.5, 0, 0))\n",
        "        bleu3 = corpus_bleu(references, hypotheses, weights=(0.33, 0.33, 0.33, 0))\n",
        "        bleu4 = corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "        # Calculate ROUGE scores\n",
        "        rouge_scores = {}\n",
        "        try:\n",
        "            # Convert tokenized hypotheses back to strings for ROUGE\n",
        "            hyp_texts = [' '.join(h) for h in hypotheses]\n",
        "            ref_texts = [' '.join(r[0]) for r in references]\n",
        "\n",
        "            rouge_scores = rouge.get_scores(hyp_texts, ref_texts, avg=True)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating ROUGE: {e}\")\n",
        "\n",
        "        # Print metrics\n",
        "        print(\"\\nEvaluation Metrics:\")\n",
        "        print(f\"BLEU-1: {bleu1:.4f}\")\n",
        "        print(f\"BLEU-2: {bleu2:.4f}\")\n",
        "        print(f\"BLEU-3: {bleu3:.4f}\")\n",
        "        print(f\"BLEU-4: {bleu4:.4f}\")\n",
        "\n",
        "        if rouge_scores:\n",
        "            print(f\"ROUGE-1: {rouge_scores['rouge-1']['f']:.4f}\")\n",
        "            print(f\"ROUGE-2: {rouge_scores['rouge-2']['f']:.4f}\")\n",
        "            print(f\"ROUGE-L: {rouge_scores['rouge-l']['f']:.4f}\")\n",
        "\n",
        "        # Return metrics dictionary\n",
        "        metrics = {\n",
        "            'bleu1': bleu1,\n",
        "            'bleu2': bleu2,\n",
        "            'bleu3': bleu3,\n",
        "            'bleu4': bleu4\n",
        "        }\n",
        "\n",
        "        if rouge_scores:\n",
        "            metrics['rouge1'] = rouge_scores['rouge-1']['f']\n",
        "            metrics['rouge2'] = rouge_scores['rouge-2']['f']\n",
        "            metrics['rougeL'] = rouge_scores['rouge-l']['f']\n",
        "\n",
        "        return metrics\n",
        "\n",
        "# ===== 5. Main Training Script =====\n",
        "\n",
        "def main():\n",
        "    # Configure paths\n",
        "    annotations_file = os.path.join(ANNOTATIONS_DIR, 'annotations.json')\n",
        "    split_file = os.path.join(METADATA_DIR, 'splits.json')\n",
        "\n",
        "    video_features_dir = os.path.join(FEATURES_DIR, 'timesformer')\n",
        "    ball_features_dir = os.path.join(FEATURES_DIR, 'ball')\n",
        "    player_features_dir = os.path.join(FEATURES_DIR, 'player')\n",
        "    basket_features_dir = os.path.join(FEATURES_DIR, 'basket')\n",
        "    court_features_dir = os.path.join(FEATURES_DIR, 'court')\n",
        "\n",
        "    # Configure model parameters\n",
        "    max_frames = 100\n",
        "    max_words = 30\n",
        "    batch_size = 32\n",
        "    embed_dim = 256\n",
        "    num_heads = 4\n",
        "    decoder_layers = 2\n",
        "\n",
        "    # Initialize tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    vocab_size = tokenizer.vocab_size\n",
        "\n",
        "    # Create datasets\n",
        "    print(\"Creating datasets...\")\n",
        "    train_dataset = NSVADataset(\n",
        "        annotations_file=annotations_file,\n",
        "        video_features_dir=video_features_dir,\n",
        "        ball_features_dir=ball_features_dir,\n",
        "        player_features_dir=player_features_dir,\n",
        "        basket_features_dir=basket_features_dir,\n",
        "        court_features_dir=court_features_dir,\n",
        "        tokenizer=tokenizer,\n",
        "        max_frames=max_frames,\n",
        "        max_words=max_words,\n",
        "        split='train',\n",
        "        split_file=split_file\n",
        "    )\n",
        "\n",
        "    val_dataset = NSVADataset(\n",
        "        annotations_file=annotations_file,\n",
        "        video_features_dir=video_features_dir,\n",
        "        ball_features_dir=ball_features_dir,\n",
        "        player_features_dir=player_features_dir,\n",
        "        basket_features_dir=basket_features_dir,\n",
        "        court_features_dir=court_features_dir,\n",
        "        tokenizer=tokenizer,\n",
        "        max_frames=max_frames,\n",
        "        max_words=max_words,\n",
        "        split='val',\n",
        "        split_file=split_file\n",
        "    )\n",
        "\n",
        "    # Create test dataset\n",
        "    test_dataset = NSVADataset(\n",
        "        annotations_file=annotations_file,\n",
        "        video_features_dir=video_features_dir,\n",
        "        ball_features_dir=ball_features_dir,\n",
        "        player_features_dir=player_features_dir,\n",
        "        basket_features_dir=basket_features_dir,\n",
        "        court_features_dir=court_features_dir,\n",
        "        tokenizer=tokenizer,\n",
        "        max_frames=max_frames,\n",
        "        max_words=max_words,\n",
        "        split='test',\n",
        "        split_file=split_file\n",
        "    )\n",
        "\n",
        "    # Create TF datasets\n",
        "    train_tf_dataset = train_dataset.create_tf_dataset(batch_size=batch_size)\n",
        "    val_tf_dataset = val_dataset.create_tf_dataset(batch_size=batch_size, shuffle=False)\n",
        "    test_tf_dataset = test_dataset.create_tf_dataset(batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize model\n",
        "    print(\"Initializing model...\")\n",
        "    model = SimplifiedSportsVideoUnderstandingModel(\n",
        "        vocab_size=vocab_size,\n",
        "        max_frames=max_frames,\n",
        "        max_words=max_words,\n",
        "        embed_dim=embed_dim,\n",
        "        num_heads=num_heads,\n",
        "        decoder_layers=decoder_layers\n",
        "    )\n",
        "\n",
        "    # Configure training\n",
        "    trainer = NSVATrainer(\n",
        "        model=model,\n",
        "        train_dataset=train_tf_dataset,\n",
        "        val_dataset=val_tf_dataset,\n",
        "        learning_rate=1e-4,\n",
        "        checkpoint_dir=CHECKPOINTS_DIR,\n",
        "        log_dir=os.path.join(RESULTS_DIR, 'logs')\n",
        "    )\n",
        "\n",
        "    # dummy_input = next(iter(train_tf_dataset))[0]\n",
        "    # _ = model(dummy_input)\n",
        "\n",
        "    # model_path = os.path.join(RESULTS_DIR, 'final_model.weights.h5')\n",
        "    # model.load_weights(model_path)\n",
        "    # print(f\"Loaded model weights from {model_path}\")\n",
        "\n",
        "    # Train model\n",
        "    epochs = 1\n",
        "    print(f\"Training for {epochs} epochs...\")\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_accuracy': [],\n",
        "        'val_loss': [],\n",
        "        'val_accuracy': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Train for one epoch\n",
        "        trainer.train_loss.reset_state()\n",
        "        trainer.train_accuracy.reset_state()\n",
        "\n",
        "        for inputs, targets in train_tf_dataset:\n",
        "            loss = trainer.train_step(inputs, targets)\n",
        "\n",
        "        # Validate\n",
        "        val_loss = trainer.validate()\n",
        "\n",
        "        # Record metrics for plotting\n",
        "        history['train_loss'].append(trainer.train_loss.result().numpy())\n",
        "        history['train_accuracy'].append(trainer.train_accuracy.result().numpy())\n",
        "        history['val_loss'].append(trainer.val_loss.result().numpy())\n",
        "        history['val_accuracy'].append(trainer.val_accuracy.result().numpy())\n",
        "\n",
        "        # Save checkpoint\n",
        "        if hasattr(trainer, 'checkpoint'):\n",
        "            trainer.checkpoint.epoch.assign_add(1)\n",
        "            save_path = trainer.checkpoint_manager.save()\n",
        "            print(f\"Saved checkpoint at: {save_path}\")\n",
        "\n",
        "    # Save final model\n",
        "    model_path = os.path.join(RESULTS_DIR, 'final_model.weights.h5')\n",
        "    model.save_weights(model_path)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    print(\"\\n===== VALIDATION RESULTS =====\")\n",
        "    val_metrics = trainer.evaluate_captions(val_tf_dataset, tokenizer, num_samples=50)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\n===== TEST RESULTS =====\")\n",
        "    test_metrics = trainer.evaluate_captions(test_tf_dataset, tokenizer, num_samples=100)\n",
        "\n",
        "    # Save metrics\n",
        "    metrics = {\n",
        "        'validation': val_metrics,\n",
        "        'test': test_metrics,\n",
        "        'history': {\n",
        "            'train_loss': [float(x) for x in history['train_loss']],\n",
        "            'train_accuracy': [float(x) for x in history['train_accuracy']],\n",
        "            'val_loss': [float(x) for x in history['val_loss']],\n",
        "            'val_accuracy': [float(x) for x in history['val_accuracy']]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    metrics_file = os.path.join(RESULTS_DIR, 'metrics.json')\n",
        "    with open(metrics_file, 'w') as f:\n",
        "        json.dump(metrics, f, indent=2)\n",
        "\n",
        "    print(f\"Evaluation metrics saved to {metrics_file}\")\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_results(history, val_metrics, test_metrics)\n",
        "\n",
        "def visualize_results(history, val_metrics, test_metrics):\n",
        "    \"\"\"\n",
        "    Visualize training history and evaluation metrics\n",
        "    \"\"\"\n",
        "    # Create results directory for plots\n",
        "    plots_dir = os.path.join(RESULTS_DIR, 'plots')\n",
        "    os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "    # Set plot style\n",
        "    plt.style.use('ggplot')\n",
        "\n",
        "    # Plot 1: Training and Validation Loss\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(history['train_loss'], label='Training Loss', marker='o', linestyle='-', linewidth=2)\n",
        "    plt.plot(history['val_loss'], label='Validation Loss', marker='s', linestyle='--', linewidth=2)\n",
        "    plt.title('Training and Validation Loss', fontsize=16)\n",
        "    plt.xlabel('Epoch', fontsize=14)\n",
        "    plt.ylabel('Loss', fontsize=14)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(plots_dir, 'loss_plot.png'))\n",
        "\n",
        "    # Plot 2: Training and Validation Accuracy\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(history['train_accuracy'], label='Training Accuracy', marker='o', linestyle='-', linewidth=2)\n",
        "    plt.plot(history['val_accuracy'], label='Validation Accuracy', marker='s', linestyle='--', linewidth=2)\n",
        "    plt.title('Training and Validation Accuracy', fontsize=16)\n",
        "    plt.xlabel('Epoch', fontsize=14)\n",
        "    plt.ylabel('Accuracy', fontsize=14)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(plots_dir, 'accuracy_plot.png'))\n",
        "\n",
        "    # Plot 3: BLEU Scores for Validation and Test\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    x = np.arange(4)\n",
        "    width = 0.35\n",
        "\n",
        "    val_bleu = [val_metrics['bleu1'], val_metrics['bleu2'], val_metrics['bleu3'], val_metrics['bleu4']]\n",
        "    test_bleu = [test_metrics['bleu1'], test_metrics['bleu2'], test_metrics['bleu3'], test_metrics['bleu4']]\n",
        "\n",
        "    plt.bar(x - width/2, val_bleu, width, label='Validation', color='#5DA5DA', alpha=0.8)\n",
        "    plt.bar(x + width/2, test_bleu, width, label='Test', color='#F15854', alpha=0.8)\n",
        "\n",
        "    plt.ylabel('Score', fontsize=14)\n",
        "    plt.title('BLEU Scores Comparison', fontsize=16)\n",
        "    plt.xticks(x, ['BLEU-1', 'BLEU-2', 'BLEU-3', 'BLEU-4'], fontsize=12)\n",
        "    plt.ylim(0, max(max(val_bleu), max(test_bleu)) * 1.2)\n",
        "\n",
        "    # Add score values on top of bars\n",
        "    for i, v in enumerate(val_bleu):\n",
        "        plt.text(i - width/2, v + 0.01, f'{v:.4f}', ha='center', fontsize=10)\n",
        "    for i, v in enumerate(test_bleu):\n",
        "        plt.text(i + width/2, v + 0.01, f'{v:.4f}', ha='center', fontsize=10)\n",
        "\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(plots_dir, 'bleu_scores.png'))\n",
        "\n",
        "    # Plot 4: ROUGE Scores for Validation and Test (if available)\n",
        "    if 'rouge1' in val_metrics and 'rouge1' in test_metrics:\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        x = np.arange(3)\n",
        "        width = 0.35\n",
        "\n",
        "        val_rouge = [val_metrics['rouge1'], val_metrics['rouge2'], val_metrics['rougeL']]\n",
        "        test_rouge = [test_metrics['rouge1'], test_metrics['rouge2'], test_metrics['rougeL']]\n",
        "\n",
        "        plt.bar(x - width/2, val_rouge, width, label='Validation', color='#5DA5DA', alpha=0.8)\n",
        "        plt.bar(x + width/2, test_rouge, width, label='Test', color='#F15854', alpha=0.8)\n",
        "\n",
        "        plt.ylabel('Score', fontsize=14)\n",
        "        plt.title('ROUGE Scores Comparison', fontsize=16)\n",
        "        plt.xticks(x, ['ROUGE-1', 'ROUGE-2', 'ROUGE-L'], fontsize=12)\n",
        "        plt.ylim(0, max(max(val_rouge), max(test_rouge)) * 1.2)\n",
        "\n",
        "        # Add score values on top of bars\n",
        "        for i, v in enumerate(val_rouge):\n",
        "            plt.text(i - width/2, v + 0.01, f'{v:.4f}', ha='center', fontsize=10)\n",
        "        for i, v in enumerate(test_rouge):\n",
        "            plt.text(i + width/2, v + 0.01, f'{v:.4f}', ha='center', fontsize=10)\n",
        "\n",
        "        plt.legend(fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(plots_dir, 'rouge_scores.png'))\n",
        "\n",
        "    print(f\"Visualization plots saved to {plots_dir}\")\n",
        "\n",
        "    # Generate a summary report with key metrics\n",
        "    summary_file = os.path.join(RESULTS_DIR, 'summary_report.md')\n",
        "    with open(summary_file, 'w') as f:\n",
        "        f.write(\"# NBA Sports Video Analysis Results\\n\\n\")\n",
        "        f.write(f\"Report generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
        "\n",
        "        f.write(\"## Training Performance\\n\\n\")\n",
        "        f.write(f\"- Final Training Loss: {history['train_loss'][-1]:.4f}\\n\")\n",
        "        f.write(f\"- Final Validation Loss: {history['val_loss'][-1]:.4f}\\n\")\n",
        "        f.write(f\"- Final Training Accuracy: {history['train_accuracy'][-1]:.4f}\\n\")\n",
        "        f.write(f\"- Final Validation Accuracy: {history['val_accuracy'][-1]:.4f}\\n\\n\")\n",
        "\n",
        "        f.write(\"## Caption Generation Evaluation\\n\\n\")\n",
        "        f.write(\"### Validation Set Metrics\\n\\n\")\n",
        "        f.write(f\"- BLEU-1: {val_metrics['bleu1']:.4f}\\n\")\n",
        "        f.write(f\"- BLEU-4: {val_metrics['bleu4']:.4f}\\n\")\n",
        "        if 'rouge1' in val_metrics:\n",
        "            f.write(f\"- ROUGE-L: {val_metrics['rougeL']:.4f}\\n\\n\")\n",
        "\n",
        "        f.write(\"### Test Set Metrics\\n\\n\")\n",
        "        f.write(f\"- BLEU-1: {test_metrics['bleu1']:.4f}\\n\")\n",
        "        f.write(f\"- BLEU-4: {test_metrics['bleu4']:.4f}\\n\")\n",
        "        if 'rouge1' in test_metrics:\n",
        "            f.write(f\"- ROUGE-L: {test_metrics['rougeL']:.4f}\\n\\n\")\n",
        "\n",
        "        f.write(\"## Visualizations\\n\\n\")\n",
        "        f.write(\"The following plots have been generated:\\n\\n\")\n",
        "        f.write(\"1. Training and Validation Loss\\n\")\n",
        "        f.write(\"2. Training and Validation Accuracy\\n\")\n",
        "        f.write(\"3. BLEU Scores Comparison (Validation vs Test)\\n\")\n",
        "        if 'rouge1' in val_metrics and 'rouge1' in test_metrics:\n",
        "            f.write(\"4. ROUGE Scores Comparison (Validation vs Test)\\n\")\n",
        "\n",
        "    print(f\"Summary report saved to {summary_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}